{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET 5 : Catégorisez automatiquement les questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLAN DE PROJET**\n",
    "1. Titre de projet : PROJET 5 - Catégorisez automatiquement les questions\n",
    "\n",
    "\n",
    "2. Chargement de bibliothèques\n",
    "\n",
    "\n",
    "3. Récupérer les données + Séparation de données en test et train\n",
    "    - Enregistrement de fichiers en .csv :\n",
    "        - X_train.csv\n",
    "        - y_train.csv\n",
    "        - X_test.csv\n",
    "        - y_test.csv\n",
    "\n",
    "\n",
    "4. Data cleaning\n",
    "    - Features :\n",
    "        - Enlever les balises HTML\n",
    "        - Enlever la ponctuation\n",
    "        - Mise en minuscule et tokenization\n",
    "        - Enlever les stopwords\n",
    "    - Target :\n",
    "        - Enlever les balises \"<>\"\n",
    "\n",
    "\n",
    "5. Feature engineering \n",
    "    - Recodage en bigrams\n",
    "    - Fusion de title, body + bigrams\n",
    "\n",
    "\n",
    "6. Analyse exploratoire\n",
    "    - Analyses univariées\n",
    "        - Description générale : Longueur de posts, nombre de tags\n",
    "        - Bag of words : Les expressions les plus fréquentes : feature & target\n",
    "            - Arrays générées:\n",
    "                - X_train_bow\n",
    "                - X_train_vocab_bow\n",
    "                - X_train_dist_bow\n",
    "                - y_train_bow\n",
    "                - y_train_vocab_bow\n",
    "                - y_train_dist_bow\n",
    "                \n",
    "                \n",
    "        - TF - IDF : Les expressions les plus fréquentes : feature & target\n",
    "             - Arrays générées:\n",
    "                  - X_train_ifidf\n",
    "                  - X_train_vocab_ifidf\n",
    "                  - X_train_dist_ifidf\n",
    "                  - y_train_ifidf\n",
    "                  - y_train_vocab_ifidf\n",
    "                  - y_train_dist_ifidf\n",
    "                  \n",
    "\n",
    "    - Analyse multivarié \n",
    "    **QUESTION : Peut-on considérer LDA comme analyse multivariée ?**\n",
    "    \n",
    "    \n",
    "    - Réduction de dimensions\n",
    "    **QUESTION : Peut-on faire un word2vec ?**\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de bibliothéques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import joblib\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "#nltk.download()  # Download text data sets, including stop words\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import re\n",
    "\n",
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Libraries for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable warning for .loc\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader les fichiers .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .csv files\n",
    "X_train = pd.read_csv('Data/X_train.csv', sep='\\t')\n",
    "X_test = pd.read_csv('Data/X_test.csv', sep='\\t')\n",
    "y_train = pd.read_csv('Data/y_train.csv', sep='\\t')\n",
    "y_test = pd.read_csv('Data/y_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le jeu de données X_train contient 9843 observations et 3 features.\n",
      "Le vecteur y_train contient 9842 observations.\n",
      "Le jeu de données X_test contient 9844 observations et 3 features.\n",
      "Le vecteur y_test contient 9843 observations.\n"
     ]
    }
   ],
   "source": [
    "# Check the loaded files\n",
    "print (\"Le jeu de données X_train contient\", X_train.shape[0], \"observations et\", X_train.shape[1], \"features.\") \n",
    "print (\"Le vecteur y_train contient\", y_train.shape[0], \"observations.\") \n",
    "print (\"Le jeu de données X_test contient\", X_test.shape[0], \"observations et\", X_test.shape[1], \"features.\") \n",
    "print (\"Le vecteur y_test contient\", y_test.shape[0], \"observations.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupérer les arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words !!! Utilité ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the arrays \n",
    "X_train_tfidf = np.load('Data/X_train_tfidf.npy')\n",
    "X_train_vocab_tfidf = np.load('Data/X_train_vocab_tfidf.npy')\n",
    "X_train_dist_tfidf = np.load('Data/X_train_dist_tfidf.npy')\n",
    "y_train_tfidf = np.load('Data/y_train_tfidf.npy')\n",
    "y_train_vocab_tfidf = np.load('Data/y_train_vocab_tfidf.npy')\n",
    "y_train_dist_tfidf = np.load('Data/y_train_dist_tfidf.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title_tfidf = np.load('Data/X_train_title_tfidf.npy')\n",
    "X_train_title_vocab_tfidf = np.load('Data/X_train_title_vocab_tfidf.npy')\n",
    "X_train_title_dist_tfidf = np.load('Data/X_train_title_dist_tfidf.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9843, 50000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the loaded arrays\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation de flags basée sur les fréquences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fréquences BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en oeuvre une méthode basée uniquement sur les fréquences des expressions (mot / bigram) utilisées dans le post et nous allons regarder si les expressions les plus fréquentes apparaissent dans le vocabulaire de tags.\n",
    "\n",
    "Tout d'abord, nous allons analyser s'il existe un ou plusieurs expressions, présentes au moins deux fois dans chaque post, qui matchent avec le vocabulaire de tags. \n",
    "\n",
    "Nous allons utiliser la décomposition en Bag of words créé dans le notebook1, chapître 6.1.2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tags vocabulary :\n",
    "y_train_vocab_bow[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The features vocabulary : \n",
    "X_train_vocab_bow[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The BOW array :\n",
    "X_train_bow[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester les fonctions sur le premier post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester notre idée sur le premier post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_post1 = X_train_bow[0]\n",
    "BOW_post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We print all expressions which are at least 2 times in the post :\n",
    "for freq, word in zip(BOW_post1, X_train_vocab_bow):\n",
    "    if freq >= 2:\n",
    "        print (freq, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compare the frequent expression to the tag's vocab:\n",
    "\n",
    "for freq, word in zip(BOW_post1, X_train_vocab_bow):\n",
    "    if freq >= 2:\n",
    "        if word in y_train_vocab_bow:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags_vect = []\n",
    "\n",
    "for freq, word in zip(BOW_post1, X_train_vocab_bow):\n",
    "    if freq >= 2:\n",
    "        if word in y_train_vocab_bow:\n",
    "            predicted_tags_vect.append(word)\n",
    "\n",
    "predicted_tags_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une fonction à appliquer sur toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maintenant, nous allons créer une fonction qui va sortir les tags pour chaque post :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_tag_freq(BOW, vocabulary, list_of_tags):\n",
    "    \n",
    "    \"\"\"Function which generates a list of tags, based on frequency of expression in a BOW object and \n",
    "    its comparison to predefined list of tags.\n",
    "    \n",
    "    Input :\n",
    "    - BOW : a BOW array\n",
    "    - vocabulary : list of BOW vocabulary\n",
    "    - list_of_tags : a list of tags\n",
    "    \n",
    "    Output :\n",
    "    - a list of predicted tags  \n",
    "    \n",
    "    \"\"\"\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for vect in range(BOW.shape[0]): \n",
    "        \n",
    "        predicted_tags_vect = [] \n",
    "        \n",
    "        for freq, word in zip(BOW[vect], vocabulary):\n",
    "            \n",
    "            if freq >= 2:\n",
    "                if word in list_of_tags:\n",
    "                    predicted_tags_vect.append(word)\n",
    "                    \n",
    "        predicted_tags.append(predicted_tags_vect)\n",
    "        \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = pred_tag_freq(X_train_bow, X_train_vocab_bow, y_train_vocab_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sauvegarder les tags prédits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the predicted tags:\n",
    "np.save('Data/predicted_tags', predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons analyser le nombre de tag prédits par la méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_tags = []\n",
    "\n",
    "for tag in range(len(predicted_tags)):\n",
    "    length = len(predicted_tags[tag])\n",
    "    nbr_tags.append(length)\n",
    "    \n",
    "nbr_tags = DataFrame(nbr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_tags[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désavantage de la méthode : nous avons des posts sans tag attribué (1875 posts) et certains posts peuvent avoir un grand nombre de tags, même si c'est plutôt rare. Nous allons appliquer la même méthode avec TF-IDF et choisir 3 tags les plus fréquents basé sur le coefficient TF-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fréquences TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est d'utiliser les fréquences TF-IDF pour avoir la main sur le nombre de tags à prédire. Cette fois-ci, la méthode sera basé sur la procédure suivante :\n",
    "\n",
    "1. Nous allons comparer toutes les expressions dans le post avec le vocabulaire de tags\n",
    "2. Nous allons attribuer à chaque expression la distance relative TF-IDF de tag\n",
    "3. Nous allons sortir 3 tags les plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29137083e+00, 2.03157824e+01, 1.77910765e+00, 1.23469745e+03,\n",
       "       7.61972597e-01, 1.03923973e+01, 1.00032151e+02, 5.74763060e+00,\n",
       "       1.16193175e+02, 2.80201636e+00])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dist_tfidf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester les fonctions sur le premier post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the array of first post\n",
    "TFIDF_post1 = X_train_tfidf[0]\n",
    "TFIDF_post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "authentication\n",
      "handle\n",
      "permissions\n",
      "plugins\n",
      "restful-authentication\n",
      "role\n",
      "using\n"
     ]
    }
   ],
   "source": [
    "#We compare the expressions in the post to the tag's vocab:\n",
    "for freq, word in zip(TFIDF_post1, X_train_vocab_tfidf):\n",
    "    if freq > 0:\n",
    "        if word in y_train_vocab_tfidf:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We list the common expressions which are in both document and the tag's vocabulary:\n",
    "\n",
    "liste_tags = []\n",
    "\n",
    "for freq, word in zip(TFIDF_post1, X_train_vocab_tfidf):\n",
    "    if freq > 0:\n",
    "        if word in y_train_vocab_tfidf:\n",
    "            liste_tags.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add',\n",
       " 'authentication',\n",
       " 'handle',\n",
       " 'permissions',\n",
       " 'plugins',\n",
       " 'restful-authentication',\n",
       " 'role',\n",
       " 'using']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2913708286761647 add\n",
      "20.315782399608562 authentication\n",
      "1.779107648085159 handle\n",
      "1234.6974528795652 permissions\n",
      "0.7619725969000765 plugins\n",
      "10.392397318668808 restful-authentication\n",
      "100.03215112054504 role\n",
      "5.747630599165471 using\n"
     ]
    }
   ],
   "source": [
    "#We zip the list with tag's relative frequency:\n",
    "\n",
    "for freq, word in zip(y_train_dist_tfidf, liste_tags):\n",
    "    print(freq, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip the tags contained in the post and tag's frequency\n",
    "liste = zip(y_train_dist_tfidf, liste_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to list\n",
    "liste = list(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.2913708286761647, 'add'),\n",
       " (20.315782399608562, 'authentication'),\n",
       " (1.779107648085159, 'handle'),\n",
       " (1234.6974528795652, 'permissions'),\n",
       " (0.7619725969000765, 'plugins'),\n",
       " (10.392397318668808, 'restful-authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (5.747630599165471, 'using')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check\n",
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the list by frequency\n",
    "liste_sort = sorted(liste, key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7619725969000765, 'plugins'),\n",
       " (1.2913708286761647, 'add'),\n",
       " (1.779107648085159, 'handle'),\n",
       " (5.747630599165471, 'using'),\n",
       " (10.392397318668808, 'restful-authentication'),\n",
       " (20.315782399608562, 'authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (1234.6974528795652, 'permissions')]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check\n",
    "liste_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract 3 most frequent tags \n",
    "tags_final = liste_sort[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20.315782399608562, 'authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (1234.6974528795652, 'permissions')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the tag's name\n",
    "tags = [x[1] for x in tags_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['authentication', 'role', 'permissions']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer la fonctions sur toutes les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous allons créer une fonction qui va sortir les tags pour chaque post :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, we will test the function on a sample\n",
    "test_sample = X_train_tfidf[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50000)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_tag_tfidf(tfidf_array, tfidf_vocabulary, list_of_tags):\n",
    "    \n",
    "    \"\"\"Function generatig a list of tags, based on frequency of expression in an TF-IDF object and \n",
    "    its comparison to predefined list of tags. \n",
    "    \n",
    "    Is the document contains more than 3 common expressions with the list of tags, the tags are sorted by the \n",
    "    TF-IDF frequency and only 3 most common tags are the predicted tags. If the document contains \n",
    "    2 or less common expressions, all the expressions are considered comme predicted tags. \n",
    "        \n",
    "    Input :\n",
    "    - tfidf_array : a TF-IDF array\n",
    "    - tfidf_vocabulary : a TF-IDF vocabulary object\n",
    "    - list_of_tags : a list of tags\n",
    "    \n",
    "    Output :\n",
    "    - a list of predicted tags  \n",
    "    \n",
    "    \"\"\"\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for doc in range(tfidf_array.shape[0]): \n",
    "       \n",
    "        #We list the common expressions which are in both document and the tag's vocabulary:   \n",
    "    \n",
    "        liste_tags = []\n",
    "\n",
    "        for freq, word in zip(tfidf_array[doc], tfidf_vocabulary):\n",
    "            if freq > 0:\n",
    "                if word in list_of_tags:\n",
    "                    liste_tags.append(word)\n",
    "                    \n",
    "        \n",
    "    \n",
    "    predicted_tags.append(liste_tags)\n",
    "    \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c#', 'file', 'fixed', 'fixed-width', 'width']]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! Regarder la fct précédente, le même pb. Indentation ???\n",
    "pred_tag_tfidf(test_sample, X_train_vocab_tfidf, y_train_vocab_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2913708286761647 add\n",
      "20.315782399608562 authentication\n",
      "1.779107648085159 handle\n",
      "1234.6974528795652 permissions\n",
      "0.7619725969000765 plugins\n",
      "10.392397318668808 restful-authentication\n",
      "100.03215112054504 role\n",
      "5.747630599165471 using\n"
     ]
    }
   ],
   "source": [
    "#We zip the list with tag's relative frequency:\n",
    "\n",
    "for freq, word in zip(y_train_dist_tfidf, liste_tags):\n",
    "    print(freq, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip the tags contained in the post and tag's frequency\n",
    "liste = zip(y_train_dist_tfidf, liste_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to list\n",
    "liste = list(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.2913708286761647, 'add'),\n",
       " (20.315782399608562, 'authentication'),\n",
       " (1.779107648085159, 'handle'),\n",
       " (1234.6974528795652, 'permissions'),\n",
       " (0.7619725969000765, 'plugins'),\n",
       " (10.392397318668808, 'restful-authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (5.747630599165471, 'using')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check\n",
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the list by frequency\n",
    "liste_sort = sorted(liste, key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7619725969000765, 'plugins'),\n",
       " (1.2913708286761647, 'add'),\n",
       " (1.779107648085159, 'handle'),\n",
       " (5.747630599165471, 'using'),\n",
       " (10.392397318668808, 'restful-authentication'),\n",
       " (20.315782399608562, 'authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (1234.6974528795652, 'permissions')]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check\n",
    "liste_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract 3 most frequent tags \n",
    "tags_final = liste_sort[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20.315782399608562, 'authentication'),\n",
       " (100.03215112054504, 'role'),\n",
       " (1234.6974528795652, 'permissions')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the tag's name\n",
    "tags = [x[1] for x in tags_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['authentication', 'role', 'permissions']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation non supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tags: 4998\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of unique tags: %d\" % len(y_train_vocab_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons faire LDA afin de trouver des sujets de posts. Etant donné que nous avons un grand nombre de tags uniques (~5k), nous allons réformuler les tags existants à l'aide de mots clés caractéristiques pour chaque sujet. \n",
    "\n",
    "Nous allons essayer de trouver un nombre de sujets optimal, pour que les sujets soient interprétables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document = titre + body + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First training of LDA : 20 topics\n",
    "no_topics = 20\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50., \n",
    "                                random_state=0).fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "triangle layoutoptions vertical-line backgroundworker grep-string uber uber-jar xamarin header-httpclient hook-script\n",
      "Topic 1\n",
      "uicollectionview (1-1) expect( 0-179684827337041 0-17968483 17968483 0-0248644019011408 17968483-0 0248644019011408-0 179684827337041\n",
      "Topic 2\n",
      "install-boost b-k largest-element find-kth kth cffi backend-c c-cffi cffi-backend wformat\n",
      "Topic 3\n",
      "android android-layout layout recyclerview layout-width parent-android layout-height parent wrap-content +id\n",
      "Topic 4\n",
      "git branch commit repository master remote push commits github pull\n",
      "Topic 5\n",
      "key-( sprache int(15) int(15)-null engine-innodb doctorsoffice varchar(100)-null default-null 0-00 00-0\n",
      "Topic 6\n",
      "jekyll specific-index osgi 04-21 21-13 46-40 13-46 linux-i686 i686-2 build-lib\n",
      "Topic 7\n",
      "blah-blah emp salary option-selected customerrors maze linkedhashmap $name aggregate-function server-reporting\n",
      "Topic 8\n",
      "get-mime 901) err(-901) err( system-err( cr-lf w-system (-core file-crlf content-uri\n",
      "Topic 9\n",
      "aop httpwebrequest difference-utf ibeacon aspectj spring-aop webclient-httpwebrequest 8-utf beacon mvnw\n",
      "Topic 10\n",
      "longer-text scaffold scaffolding text-longer text-second superior-text text-block text-4 elit-aenean eget-dolor\n",
      "Topic 11\n",
      "underline io-12 flex-basis 12-safari io-11 dark-color scale-1 user-scalable name-viewport content-width\n",
      "Topic 12\n",
      "(min-width juggernaut difference-math screen-(min 768px) width-768px) medium-(min c')) path-join('src' glob(os-path\n",
      "Topic 13\n",
      "file like string code get difference class function java python\n",
      "Topic 14\n",
      "mysql-jdbc com-mysql java-sql html-parser (get-post automapper r-version integer-binary rstudio county'\n",
      "Topic 15\n",
      "cloudfront hungarian $# attr-accessor iterm2 make-column ie-http weingartner weingartner-weincad weincad\n",
      "Topic 16\n",
      "equivalent-java's '28-aug '28 difference-collection aug-2008' 2008' 2008'-'28 exch aug-2008') 2008')\n",
      "Topic 17\n",
      "implement-singleton isolation-level 147 rbenv 153 cpu-bound nant event1 483 12px\n",
      "Topic 18\n",
      "whatsapp matching-line agile myisam kafka get-highlighted arraydeque on() text-page difference-asynchronous\n",
      "Topic 19\n",
      "strongly-typed auto-format multicore stdcall multicore-programming weakly-typed calling-convention cdecl companycd displaynameattribute\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "\n",
    "display_topics(lda, X_train_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que certains sujets sont difficile à interpréter : Nous allons entraîner le modèle à nouveau, cette fois-ci avec 10 sujets. Nous allons aussi réduire le nombre d'expressions clés dans l'affichage, nous allons regarder seulement 5 premiers mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second LDA training : 10 topics\n",
    "no_topics = 10\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50., \n",
    "                                random_state=0).fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "file like string code get\n",
      "Topic 1\n",
      "width-200px place-answer chatroom underline multicore\n",
      "Topic 2\n",
      "equivalent-java's get-mime $pid sudo-ip netns\n",
      "Topic 3\n",
      "var2 metaclasses pclass com-mysql matching-line\n",
      "Topic 4\n",
      "aggregation-composition aggregation composition difference-aggregation (get-post\n",
      "Topic 5\n",
      "father mediumint bigint largest-element father-father\n",
      "Topic 6\n",
      "weakhashmap jekyll mm4-s2 mm4 mm2\n",
      "Topic 7\n",
      "linkedhashmap if(one &&-two else-if(one session-timeout\n",
      "Topic 8\n",
      "difference-math size-byte (bytes debug1 catalina\n",
      "Topic 9\n",
      "android layout android-layout fragment recyclerview\n"
     ]
    }
   ],
   "source": [
    "# Display 5 top words\n",
    "\n",
    "no_top_words = 5\n",
    "display_topics(lda, X_train_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third LDA training : 5 topics\n",
    "no_topics = 5\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=10,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=100., \n",
    "                                random_state=0).fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "aggregation-composition aggregation metaclasses composition great-great difference-aggregation difference-set father 'sdfd' agile-development\n",
      "Topic 1\n",
      "weakhashmap faq place-answer eri debug1 c++-faq would-place meta-started chatroom-faq (note-meant\n",
      "Topic 2\n",
      "multicore-programming multicore aspectj airport longer-text put( spring-aop 12px org-gradle '28-aug\n",
      "Topic 3\n",
      "interpreter-compiler attr-accessor '2010-10 '2010 147 drawnum page-text 153 jekyll $uuid\n",
      "Topic 4\n",
      "file like string code get git difference android class function\n"
     ]
    }
   ],
   "source": [
    "# Display 5 top words\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(lda, X_train_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th LDA training : 3 topics\n",
    "no_topics = 3\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=10,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=100., \n",
    "                                random_state=0).fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "file like string code get git difference android class function\n",
      "Topic 1\n",
      "weakhashmap faq place-answer interpreter-compiler father 'sdfd' '2010 '2010-10 drawnum eri\n",
      "Topic 2\n",
      "aggregation-composition aggregation composition metaclasses difference-aggregation multicore-programming 147 bitcode 'group' 'sub'\n"
     ]
    }
   ],
   "source": [
    "# Display 5 top words\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(lda, X_train_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même en modifiant les paramètres, nous n'avons pas trouvé des sujets faciles à interpréter et à reformuler. Nous allons essayer de changer la forme de \"document\" qui rentre dans le modèle. Nous allons cette fois-ci étudier uniquement le titre de text sans bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document = titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First training of LDA : 20 topics\n",
    "no_topics = 20\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50., \n",
    "                                random_state=0).fit(X_train_title_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "single multi double iphone core animation removing advantage border audio\n",
      "Topic 1\n",
      "file string get android text javascript check python html command\n",
      "Topic 2\n",
      "rail controller model django exception loop react template wpf global\n",
      "Topic 3\n",
      "image android build cs debug background loading performance uiview gradle\n",
      "Topic 4\n",
      "many laravel stage composer uiimageview relationship ctags poco oop unstaged\n",
      "Topic 5\n",
      "j jquery node request http element post practice remove save\n",
      "Topic 6\n",
      "ruby package hash pip start learning install available (or gcc\n",
      "Topic 7\n",
      "difference what's framework xcode test copy thread entity swift read\n",
      "Topic 8\n",
      "git branch list commit array remote repository merge string file\n",
      "Topic 9\n",
      "call feature hidden service log useful dot intellij python keyboard\n",
      "Topic 10\n",
      "github directory disable tree repo entire define basic pdf proxy\n",
      "Topic 11\n",
      "function c c++ object javascript studio variable python mean library\n",
      "Topic 12\n",
      "date time query std statement join format result return fixed\n",
      "Topic 13\n",
      "php center div align bottom session vertically scrolling constraint timeout\n",
      "Topic 14\n",
      "programming getting language chrome developer created assembly functional undo void\n",
      "Topic 15\n",
      "memory source collection support mongodb display long take usage iterate\n",
      "Topic 16\n",
      "java class type generic certificate interface exactly difference abstract numpy\n",
      "Topic 17\n",
      "column table row docker panda multiple argument mysql r name\n",
      "Topic 18\n",
      "net mvc asp operator local json master web common block\n",
      "Topic 19\n",
      "sql server google include access angularjs restful store versus client\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "\n",
    "display_topics(lda, X_train_title_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second LDA training : 10 topics\n",
    "no_topics = 10\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50., \n",
    "                                random_state=0).fit(X_train_title_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "jquery element android cs image get html event url set\n",
      "Topic 1\n",
      "string python mysql text function return character php bash memory\n",
      "Topic 2\n",
      "sql table swift row column server index panda eclipse parameter\n",
      "Topic 3\n",
      "database postgresql mac o fragment sort collection date byte map\n",
      "Topic 4\n",
      "code programming template source language color context callback exit back\n",
      "Topic 5\n",
      "git file branch repository request window commit j remote install\n",
      "Topic 6\n",
      "docker exception container stack wpf global uiview regex define place\n",
      "Topic 7\n",
      "java object file javascript difference net array python class variable\n",
      "Topic 8\n",
      "difference std linq active purpose utf what's unicode jpa storyboard\n",
      "Topic 9\n",
      "vim remove case dictionary space string binary terminal scala tree\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "\n",
    "display_topics(lda, X_train_title_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second LDA training : 5 topics\n",
    "no_topics = 5\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50., \n",
    "                                random_state=0).fit(X_train_title_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "string file python javascript java get function array object list\n",
      "Topic 1\n",
      "git branch repository file commit remote practice difference local date\n",
      "Topic 2\n",
      "difference output language algorithm exception c++ template word thread equivalent\n",
      "Topic 3\n",
      "j node request http number column test io panda post\n",
      "Topic 4\n",
      "code sql table server mysql database android vim mean query\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "\n",
    "display_topics(lda, X_train_title_vocab_tfidf, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA nous n'a pas permis d'identifier des sujets précis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN + word2vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! A tester\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
